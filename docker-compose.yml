services:
  search:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./src:/app/src
    environment:
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION}
      - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-dagsordener}
      - FLAGSERVE_URL=${FLAGSERVE_URL:-http://flagserve:8273}
      - FLAGSERVE_API_KEY=${FLAGSERVE_API_KEY:-}
    depends_on:
      - qdrant
      - flagserve
    restart: unless-stopped

  chainlit:
    build:
      context: .
      dockerfile: Dockerfile.chainlit
    ports:
      - "8001:8001"
    environment:
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION}
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-dagsordener}
      - FLAGSERVE_URL=http://flagserve:8273
      - FLAGSERVE_API_KEY=${FLAGSERVE_API_KEY:-}
    depends_on:
      - qdrant
      - flagserve
    restart: unless-stopped

  completions:
    build: .
    command: ["python", "-m", "uvicorn", "completions:app", "--host", "0.0.0.0", "--port", "8002"]
    ports:
      - "8002:8002"
    environment:
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION}
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-dagsordener}
      - FLAGSERVE_URL=http://flagserve:8273
      - FLAGSERVE_API_KEY=${FLAGSERVE_API_KEY:-}
      - COMPLETIONS_API_KEY=${COMPLETIONS_API_KEY:-}
    depends_on:
      - qdrant
      - flagserve
    restart: unless-stopped

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "8080:8080"
    environment:
      - OPENAI_API_BASE_URL=http://completions:8002/v1
      - OPENAI_API_KEY=${COMPLETIONS_API_KEY:-dummy}
      - WEBUI_AUTH=false
    volumes:
      - openwebui_data:/app/backend/data
    depends_on:
      - completions
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    restart: unless-stopped

  flagserve:
    image: jakobmwang/flagserve:latest
    shm_size: 2gb
    ports:
      - "8273:8273"
    environment:
      - BGE_EMBED_MODEL=${BGE_EMBED_MODEL:-BAAI/bge-m3}
      - BGE_RERANK_MODEL=${BGE_RERANK_MODEL:-BAAI/bge-reranker-v2-m3}
      - BGE_MAX_BATCH_SIZE=${BGE_MAX_BATCH_SIZE:-64}
      - BGE_BATCH_TIMEOUT_S=${BGE_BATCH_TIMEOUT_S:-0.03}
      - BGE_USE_FP16=${BGE_USE_FP16:-true}
      - BGE_ENABLE_EMBED=${BGE_ENABLE_EMBED:-true}
      - BGE_ENABLE_RERANK=${BGE_ENABLE_RERANK:-true}
      - FLAGSERVE_DEVICE=${FLAGSERVE_DEVICE:-cuda}
      - FLAGSERVE_API_KEY=${FLAGSERVE_API_KEY:-}
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - hf-cache:/home/appuser/.cache/huggingface
    restart: unless-stopped

volumes:
  qdrant_data:
  hf-cache:
  openwebui_data: